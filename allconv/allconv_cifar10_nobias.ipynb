{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "(32, 32, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.9608 - acc: 0.2644Epoch 00000: val_acc improved from -inf to 0.40540, saving model to weights.hdf5\n",
      "1562/1562 [==============================] - 880s - loss: 1.9606 - acc: 0.2644 - val_loss: 1.6570 - val_acc: 0.4054\n",
      "Epoch 2/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.6527 - acc: 0.3953Epoch 00001: val_acc improved from 0.40540 to 0.44010, saving model to weights.hdf5\n",
      "1562/1562 [==============================] - 857s - loss: 1.6527 - acc: 0.3953 - val_loss: 1.5247 - val_acc: 0.4401\n",
      "Epoch 3/100\n",
      "1310/1562 [========================>.....] - ETA: 124s - loss: 1.5777 - acc: 0.4250"
     ]
    }
   ],
   "source": [
    "# adapted from https://github.com/MateLabs/All-Conv-Keras/blob/master/allconv.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D, merge\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "\n",
    "rows, cols = 32, 32\n",
    "\n",
    "channels = 3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "print (X_train.shape[1:])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), padding = 'same', use_bias=False, input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3),padding='same', use_bias=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(96, (3, 3), padding='same', use_bias=False, strides = (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding = 'same', use_bias=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3),padding='same', use_bias=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (3, 3),padding='same', use_bias=False, strides = (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), padding = 'same', use_bias=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(192, (1, 1),padding='valid', use_bias=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(10, (1, 1), padding='valid', use_bias=False))\n",
    "\n",
    "\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(X_train)\n",
    "filepath=\"nobias_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history_callback = model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0]//batch_size,\n",
    "                        epochs=nb_epoch, validation_data=(X_test, Y_test), callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "pandas.DataFrame(history_callback.history).to_csv(\"nobias_history.csv\")\n",
    "\n",
    "model.save('nobias_keras_allconv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}