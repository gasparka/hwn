{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 144s - loss: 1.8754 - acc: 0.3066 - val_loss: 1.6121 - val_acc: 0.4042\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.5308 - acc: 0.4518 - val_loss: 1.8003 - val_acc: 0.3996\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 92s - loss: 1.3660 - acc: 0.5181 - val_loss: 1.2624 - val_acc: 0.5490\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 96s - loss: 1.2521 - acc: 0.5620 - val_loss: 1.2324 - val_acc: 0.5716\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.1784 - acc: 0.5898 - val_loss: 1.2324 - val_acc: 0.5692\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 91s - loss: 1.1257 - acc: 0.6075 - val_loss: 1.1224 - val_acc: 0.6067\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.0786 - acc: 0.6247 - val_loss: 1.0231 - val_acc: 0.6565\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 92s - loss: 1.0469 - acc: 0.6396 - val_loss: 0.9674 - val_acc: 0.6688\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 91s - loss: 1.0076 - acc: 0.6537 - val_loss: 0.9728 - val_acc: 0.6667\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 97s - loss: 0.9786 - acc: 0.6666 - val_loss: 0.9759 - val_acc: 0.6657\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 98s - loss: 0.9623 - acc: 0.6686 - val_loss: 1.0706 - val_acc: 0.6525\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 96s - loss: 0.9391 - acc: 0.6779 - val_loss: 0.9600 - val_acc: 0.6735\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 94s - loss: 0.9284 - acc: 0.6833 - val_loss: 1.0830 - val_acc: 0.6523\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 91s - loss: 0.9153 - acc: 0.6856 - val_loss: 0.9851 - val_acc: 0.6777\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 99s - loss: 0.9101 - acc: 0.6859 - val_loss: 0.8772 - val_acc: 0.7067\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 99s - loss: 0.9050 - acc: 0.6918 - val_loss: 0.9070 - val_acc: 0.7039\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 94s - loss: 0.9005 - acc: 0.6945 - val_loss: 0.8303 - val_acc: 0.7209\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 99s - loss: 0.8979 - acc: 0.6927 - val_loss: 0.8892 - val_acc: 0.7122\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 99s - loss: 0.8931 - acc: 0.6984 - val_loss: 0.9763 - val_acc: 0.6887\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 95s - loss: 0.8903 - acc: 0.6987 - val_loss: 0.9928 - val_acc: 0.6873\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 97s - loss: 0.8912 - acc: 0.7008 - val_loss: 0.8068 - val_acc: 0.7319\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 97s - loss: 0.8861 - acc: 0.6997 - val_loss: 0.9787 - val_acc: 0.6847\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 94s - loss: 0.9078 - acc: 0.6952 - val_loss: 0.9448 - val_acc: 0.7005\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 92s - loss: 0.9110 - acc: 0.6934 - val_loss: 0.9107 - val_acc: 0.7114\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 98s - loss: 0.9144 - acc: 0.6913 - val_loss: 0.9793 - val_acc: 0.6816\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 100s - loss: 0.9201 - acc: 0.6909 - val_loss: 0.8632 - val_acc: 0.7239\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 97s - loss: 0.9273 - acc: 0.6878 - val_loss: 0.8791 - val_acc: 0.7181\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 96s - loss: 0.9402 - acc: 0.6842 - val_loss: 0.8755 - val_acc: 0.7140\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 95s - loss: 0.9580 - acc: 0.6812 - val_loss: 1.0716 - val_acc: 0.6526\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 98s - loss: 0.9583 - acc: 0.6816 - val_loss: 0.9456 - val_acc: 0.6923\n",
      "Epoch 31/250\n",
      "50000/50000 [==============================] - 94s - loss: 0.9709 - acc: 0.6746 - val_loss: 0.9846 - val_acc: 0.6766\n",
      "Epoch 32/250\n",
      "50000/50000 [==============================] - 100s - loss: 0.9874 - acc: 0.6718 - val_loss: 0.9128 - val_acc: 0.6976\n",
      "Epoch 33/250\n",
      "50000/50000 [==============================] - 95s - loss: 0.9811 - acc: 0.6739 - val_loss: 1.2531 - val_acc: 0.5890\n",
      "Epoch 34/250\n",
      "50000/50000 [==============================] - 99s - loss: 0.9919 - acc: 0.6721 - val_loss: 0.9347 - val_acc: 0.6950\n",
      "Epoch 35/250\n",
      "50000/50000 [==============================] - 98s - loss: 1.0178 - acc: 0.6651 - val_loss: 1.0017 - val_acc: 0.6745\n",
      "Epoch 36/250\n",
      "50000/50000 [==============================] - 99s - loss: 1.0104 - acc: 0.6648 - val_loss: 1.1239 - val_acc: 0.6283\n",
      "Epoch 37/250\n",
      "50000/50000 [==============================] - 97s - loss: 1.0271 - acc: 0.6596 - val_loss: 0.9630 - val_acc: 0.6890\n",
      "Epoch 38/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.0394 - acc: 0.6551 - val_loss: 1.2945 - val_acc: 0.5816\n",
      "Epoch 39/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.0573 - acc: 0.6516 - val_loss: 1.1581 - val_acc: 0.6075\n",
      "Epoch 40/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.0420 - acc: 0.6584 - val_loss: 1.3436 - val_acc: 0.5843\n",
      "Epoch 41/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.0511 - acc: 0.6542 - val_loss: 1.0730 - val_acc: 0.6526\n",
      "Epoch 42/250\n",
      "50000/50000 [==============================] - 100s - loss: 1.0761 - acc: 0.6469 - val_loss: 1.0075 - val_acc: 0.6849\n",
      "Epoch 43/250\n",
      "50000/50000 [==============================] - 98s - loss: 1.0695 - acc: 0.6484 - val_loss: 1.0189 - val_acc: 0.6712\n",
      "Epoch 44/250\n",
      "50000/50000 [==============================] - 97s - loss: 1.0711 - acc: 0.6460 - val_loss: 1.0362 - val_acc: 0.6658\n",
      "Epoch 45/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.0772 - acc: 0.6457 - val_loss: 0.9107 - val_acc: 0.7012\n",
      "Epoch 46/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.0972 - acc: 0.6409 - val_loss: 1.2902 - val_acc: 0.5786\n",
      "Epoch 47/250\n",
      "50000/50000 [==============================] - 96s - loss: 1.0974 - acc: 0.6408 - val_loss: 1.0263 - val_acc: 0.6679\n",
      "Epoch 48/250\n",
      "50000/50000 [==============================] - 97s - loss: 1.1279 - acc: 0.6321 - val_loss: 1.0419 - val_acc: 0.6593\n",
      "Epoch 49/250\n",
      "50000/50000 [==============================] - 101s - loss: 1.1412 - acc: 0.6303 - val_loss: 1.1401 - val_acc: 0.6329\n",
      "Epoch 50/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.1446 - acc: 0.6281 - val_loss: 1.3494 - val_acc: 0.5522\n",
      "Epoch 51/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.1552 - acc: 0.6236 - val_loss: 1.0908 - val_acc: 0.6442\n",
      "Epoch 52/250\n",
      "50000/50000 [==============================] - 101s - loss: 1.1618 - acc: 0.6225 - val_loss: 1.3095 - val_acc: 0.5977\n",
      "Epoch 53/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.1803 - acc: 0.6152 - val_loss: 1.5066 - val_acc: 0.4957\n",
      "Epoch 54/250\n",
      "50000/50000 [==============================] - 97s - loss: 1.1943 - acc: 0.6144 - val_loss: 1.4609 - val_acc: 0.5086\n",
      "Epoch 55/250\n",
      "50000/50000 [==============================] - 93s - loss: 1.2247 - acc: 0.6054 - val_loss: 1.4959 - val_acc: 0.5390\n",
      "Epoch 56/250\n",
      "50000/50000 [==============================] - 99s - loss: 1.2729 - acc: 0.5898 - val_loss: 1.3506 - val_acc: 0.5608\n",
      "Epoch 57/250\n",
      "50000/50000 [==============================] - 100s - loss: 1.2839 - acc: 0.5852 - val_loss: 1.2875 - val_acc: 0.5772\n",
      "Epoch 58/250\n",
      "50000/50000 [==============================] - 95s - loss: 1.2785 - acc: 0.5890 - val_loss: 1.3625 - val_acc: 0.5800\n",
      "Epoch 59/250\n",
      "50000/50000 [==============================] - 98s - loss: 1.3243 - acc: 0.5752 - val_loss: 1.4533 - val_acc: 0.5260\n",
      "Epoch 60/250\n",
      "50000/50000 [==============================] - 94s - loss: 1.3225 - acc: 0.5724 - val_loss: 1.4254 - val_acc: 0.5662\n",
      "Epoch 61/250\n",
      "50000/50000 [==============================] - 96s - loss: 1.3504 - acc: 0.5622 - val_loss: 1.2738 - val_acc: 0.5819\n",
      "Epoch 62/250\n",
      "50000/50000 [==============================] - 92s - loss: 1.3815 - acc: 0.5536 - val_loss: 2.1860 - val_acc: 0.2015\n",
      "Epoch 63/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 91s - loss: 1.5401 - acc: 0.5068 - val_loss: 2.1786 - val_acc: 0.2056\n",
      "Epoch 64/250\n",
      "50000/50000 [==============================] - 97s - loss: 1.6218 - acc: 0.4774 - val_loss: 1.6470 - val_acc: 0.4796\n",
      "Epoch 65/250\n",
      "50000/50000 [==============================] - 92s - loss: 1.5341 - acc: 0.5022 - val_loss: 1.9606 - val_acc: 0.3020\n",
      "Epoch 66/250\n",
      "50000/50000 [==============================] - 89s - loss: 1.5632 - acc: 0.4944 - val_loss: 1.4692 - val_acc: 0.5484\n",
      "Epoch 67/250\n",
      "50000/50000 [==============================] - 91s - loss: 1.8402 - acc: 0.3669 - val_loss: 1.8715 - val_acc: 0.3765\n",
      "Epoch 68/250\n",
      "50000/50000 [==============================] - 91s - loss: 1.6499 - acc: 0.4584 - val_loss: 2.1999 - val_acc: 0.2494\n",
      "Epoch 69/250\n",
      "50000/50000 [==============================] - 91s - loss: 1.7240 - acc: 0.4343 - val_loss: 1.9310 - val_acc: 0.3758\n",
      "Epoch 70/250\n",
      "50000/50000 [==============================] - 89s - loss: 1.9960 - acc: 0.3208 - val_loss: 2.1407 - val_acc: 0.1938\n",
      "Epoch 71/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.2358 - acc: 0.1581 - val_loss: 2.3024 - val_acc: 0.0991\n",
      "Epoch 72/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.1599 - acc: 0.1948 - val_loss: 2.1550 - val_acc: 0.2237\n",
      "Epoch 73/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.1197 - acc: 0.2458 - val_loss: 2.6566 - val_acc: 0.1770\n",
      "Epoch 74/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.1211 - acc: 0.2446 - val_loss: 2.0787 - val_acc: 0.2659\n",
      "Epoch 75/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.1519 - acc: 0.2171 - val_loss: 2.2940 - val_acc: 0.1044\n",
      "Epoch 76/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.2754 - acc: 0.1361 - val_loss: 2.2945 - val_acc: 0.1046\n",
      "Epoch 77/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.1425 - acc: 0.2175 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 78/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.1146 - acc: 0.2255 - val_loss: 2.1300 - val_acc: 0.2162\n",
      "Epoch 79/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.0187 - acc: 0.2778 - val_loss: 1.9565 - val_acc: 0.2988\n",
      "Epoch 80/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.0719 - acc: 0.2619 - val_loss: 2.1685 - val_acc: 0.1898\n",
      "Epoch 81/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.0132 - acc: 0.2828 - val_loss: 1.9252 - val_acc: 0.3141\n",
      "Epoch 82/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.0168 - acc: 0.2763 - val_loss: 1.9313 - val_acc: 0.3040\n",
      "Epoch 83/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.0393 - acc: 0.2725 - val_loss: 1.9842 - val_acc: 0.2643\n",
      "Epoch 84/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.0376 - acc: 0.2751 - val_loss: 2.2580 - val_acc: 0.1222\n",
      "Epoch 85/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.0717 - acc: 0.2628 - val_loss: 1.9793 - val_acc: 0.3228\n",
      "Epoch 86/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.0716 - acc: 0.2674 - val_loss: 2.2861 - val_acc: 0.1099\n",
      "Epoch 87/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.1368 - acc: 0.2460 - val_loss: 2.2677 - val_acc: 0.1176\n",
      "Epoch 88/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.1035 - acc: 0.2529 - val_loss: 2.2623 - val_acc: 0.1213\n",
      "Epoch 89/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.2277 - acc: 0.1896 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 90/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.2223 - acc: 0.1873 - val_loss: 2.3011 - val_acc: 0.1008\n",
      "Epoch 91/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.2616 - acc: 0.1592 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 92/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3072 - acc: 0.1033 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 93/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.2016 - acc: 0.1985 - val_loss: 2.2871 - val_acc: 0.1091\n",
      "Epoch 94/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.1535 - acc: 0.2430 - val_loss: 2.2793 - val_acc: 0.1111\n",
      "Epoch 95/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.2442 - acc: 0.1590 - val_loss: 2.3017 - val_acc: 0.1004\n",
      "Epoch 96/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.2851 - acc: 0.1440 - val_loss: 2.2999 - val_acc: 0.1012\n",
      "Epoch 97/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.2852 - acc: 0.1645 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 98/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3053 - acc: 0.1016 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 99/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3051 - acc: 0.1001 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 100/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 101/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3025 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 102/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 103/250\n",
      "50000/50000 [==============================] - 99s - loss: 2.3025 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 104/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 105/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 106/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 107/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 108/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 109/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 110/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 111/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 112/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 113/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 114/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 115/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3028 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 116/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 117/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 118/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 119/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 120/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 121/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 122/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 123/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 124/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 126/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 127/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 128/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3025 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 129/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 130/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 131/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 132/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3031 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 133/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 134/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 135/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 136/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 137/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 138/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 139/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 140/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 141/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 142/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 143/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 144/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 145/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 146/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 147/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 148/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 149/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 150/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 151/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 152/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 153/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 154/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 155/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 156/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 157/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 158/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 159/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 160/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 161/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 162/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 163/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3027 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 164/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 165/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 166/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 167/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 168/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 169/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 170/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 171/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 172/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 173/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 174/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 175/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 176/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 177/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 178/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 179/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 180/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 181/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 182/250\n",
      "50000/50000 [==============================] - 99s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 183/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 184/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 185/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 186/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 187/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 88s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 188/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 189/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 190/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 191/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 192/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 193/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 194/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 195/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 196/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 197/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 198/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 199/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 200/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 201/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 202/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 203/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 204/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 205/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 206/250\n",
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 207/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 208/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 209/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 210/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 211/250\n",
      "50000/50000 [==============================] - 96s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 212/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 213/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 214/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 215/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 216/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 217/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 218/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 219/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 220/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 221/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 222/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 223/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 224/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 225/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3025 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 226/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 227/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 228/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 229/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 230/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 231/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 232/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 233/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 234/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 235/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 236/250\n",
      "50000/50000 [==============================] - 90s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 237/250\n",
      "50000/50000 [==============================] - 91s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 238/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 239/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 240/250\n",
      "50000/50000 [==============================] - 94s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 241/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 242/250\n",
      "50000/50000 [==============================] - 93s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 243/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 244/250\n",
      "50000/50000 [==============================] - 98s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 245/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 246/250\n",
      "50000/50000 [==============================] - 95s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 247/250\n",
      "50000/50000 [==============================] - 99s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 248/250\n",
      "50000/50000 [==============================] - 92s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 249/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 89s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 250/250\n",
      "50000/50000 [==============================] - 97s - loss: 2.3026 - acc: 0.1000 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Test loss: 2.30258512497\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatx=float32 python cifar10_cnn.py\n",
    "It gets down to 0.65 test logloss in 25 epochs, and down to 0.55 after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 250\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', use_bias=False, input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', use_bias=False))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', use_bias=False, strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', use_bias=False))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', use_bias=False))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', use_bias=False, strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(num_classes, (1, 1), activation='relu', use_bias=False))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "model.save('cifar10_base')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cifar10_globalavg_25ep')\n",
    "# model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 3, 32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.layers[0].get_weights()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 32, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.layers[4].get_weights()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[  2.26638600e-01,  -3.66327196e-01,  -2.70816367e-02, ...,\n",
       "            -3.30585986e-01,  -4.42860007e-01,   1.03598922e-01],\n",
       "          [  2.51502812e-01,   7.30787888e-02,   2.46326759e-01, ...,\n",
       "             2.29454368e-01,  -1.74416155e-01,   6.97132722e-02],\n",
       "          [  5.18631637e-02,   7.32588321e-02,   1.89953238e-01, ...,\n",
       "            -2.94342786e-01,  -1.11988463e-01,  -3.85406911e-01],\n",
       "          ..., \n",
       "          [  6.06607944e-02,  -7.42304385e-01,  -6.87854216e-02, ...,\n",
       "            -1.34996414e-01,   9.88706797e-02,  -2.40444481e-01],\n",
       "          [  3.60393859e-02,  -1.76986724e-01,  -1.24336556e-02, ...,\n",
       "            -6.89748256e-03,   2.42830172e-01,  -2.89227486e-01],\n",
       "          [  4.99344654e-02,   1.93324104e-01,   4.41755839e-02, ...,\n",
       "             1.79024056e-01,  -3.02707702e-02,  -2.18332157e-01]],\n",
       "\n",
       "         [[  3.11181664e-01,  -3.30501348e-02,  -1.55259326e-01, ...,\n",
       "            -3.11373055e-01,  -3.20470840e-01,   2.30225235e-01],\n",
       "          [  1.89826623e-01,  -2.50285953e-01,  -6.80130869e-02, ...,\n",
       "            -2.57819325e-01,   4.28230725e-02,   7.19873756e-02],\n",
       "          [  5.40883839e-02,  -9.49246734e-02,  -1.50146186e-01, ...,\n",
       "            -2.21160635e-01,  -1.45461053e-01,  -3.19579720e-01],\n",
       "          ..., \n",
       "          [  1.20879158e-01,  -9.46214497e-02,   3.56942229e-02, ...,\n",
       "             7.19362870e-02,   8.26233923e-02,  -2.47988790e-01],\n",
       "          [ -3.56993377e-01,  -3.71036857e-01,   4.84229177e-02, ...,\n",
       "             5.83844520e-02,  -4.94668707e-02,  -2.98405230e-01],\n",
       "          [  1.03047684e-01,  -9.93923768e-02,   8.99870396e-02, ...,\n",
       "            -3.69258709e-02,   6.66971877e-02,  -3.18114460e-01]],\n",
       "\n",
       "         [[  1.18541144e-01,  -1.46358624e-01,   1.43901885e-01, ...,\n",
       "            -4.39405851e-02,  -3.98883075e-01,   1.08679824e-01],\n",
       "          [  1.04656599e-01,   1.43928498e-01,   2.22249832e-02, ...,\n",
       "            -6.34581447e-02,   4.00805585e-02,   9.56897959e-02],\n",
       "          [  2.06148648e-03,  -1.76439896e-01,   8.94547701e-02, ...,\n",
       "             1.18565395e-01,  -1.14008524e-01,  -3.17851841e-01],\n",
       "          ..., \n",
       "          [  2.21014693e-02,  -1.03474252e-01,   1.67996645e-01, ...,\n",
       "             1.61981836e-01,  -1.68776244e-01,  -3.55693519e-01],\n",
       "          [ -2.23622113e-01,   4.80698012e-02,  -1.71604365e-01, ...,\n",
       "             4.30217162e-02,  -1.53485447e-01,  -9.45927575e-02],\n",
       "          [  3.26450430e-02,   2.95558888e-02,  -9.92675722e-02, ...,\n",
       "            -3.36542614e-02,   9.85438079e-02,  -1.12207167e-01]]],\n",
       "\n",
       "\n",
       "        [[[  4.14120942e-01,  -3.92006040e-01,  -1.29635200e-01, ...,\n",
       "            -3.18999618e-01,  -7.09689856e-02,  -7.60043738e-03],\n",
       "          [  1.04445256e-01,  -3.68776709e-01,   2.06257761e-01, ...,\n",
       "             1.90961644e-01,  -2.95712471e-01,  -3.52315642e-02],\n",
       "          [  1.98893145e-01,  -2.17356533e-01,   1.63717002e-01, ...,\n",
       "            -3.73069853e-01,  -3.76505479e-02,   2.07615241e-01],\n",
       "          ..., \n",
       "          [  1.67440191e-01,  -3.77456516e-01,   2.79454165e-04, ...,\n",
       "            -1.22763984e-01,   1.05161620e-02,   1.23441726e-01],\n",
       "          [ -9.00998861e-02,  -3.31147224e-01,  -5.35575636e-02, ...,\n",
       "            -1.00731917e-01,  -4.55141552e-02,   4.06991355e-02],\n",
       "          [  7.26883560e-02,   1.59039591e-02,   4.46664244e-02, ...,\n",
       "             9.00379494e-02,  -3.87557447e-02,  -1.82552077e-02]],\n",
       "\n",
       "         [[  3.69063020e-01,  -2.24388197e-01,  -2.91683108e-01, ...,\n",
       "            -5.67553282e-01,  -2.30321765e-01,  -6.30391687e-02],\n",
       "          [  1.45629093e-01,  -2.10129529e-01,  -2.55025893e-01, ...,\n",
       "            -3.04073572e-01,   1.46572113e-01,   1.19705789e-01],\n",
       "          [  2.73669630e-01,   3.86979170e-02,  -2.86362827e-01, ...,\n",
       "             4.22101393e-02,  -1.03209078e-01,   1.48542494e-01],\n",
       "          ..., \n",
       "          [  1.91339273e-02,   7.90528283e-02,  -9.47591662e-02, ...,\n",
       "             1.11514464e-01,   6.03773296e-02,   1.56103835e-01],\n",
       "          [  2.40209084e-02,  -4.80890647e-02,   4.61222157e-02, ...,\n",
       "             3.46562937e-02,   1.19093485e-01,   3.34556513e-02],\n",
       "          [  9.04861242e-02,  -1.98839888e-01,   1.01687424e-01, ...,\n",
       "            -1.59513965e-01,   8.93943682e-02,   1.11815847e-01]],\n",
       "\n",
       "         [[  3.85337561e-01,  -3.26843470e-01,  -6.69130534e-02, ...,\n",
       "            -2.37263829e-01,  -2.15118945e-01,  -2.94650812e-02],\n",
       "          [  1.05687812e-01,   3.74439210e-02,   6.25494868e-03, ...,\n",
       "             5.15325777e-02,  -4.41026352e-02,   1.51751414e-01],\n",
       "          [  8.25602561e-02,  -1.77066043e-01,   2.45796666e-01, ...,\n",
       "             1.67720631e-01,   3.42860036e-02,   9.07851085e-02],\n",
       "          ..., \n",
       "          [  1.40356258e-01,   5.17372079e-02,   1.66670993e-01, ...,\n",
       "             5.90910241e-02,   6.94327876e-02,   1.05448142e-01],\n",
       "          [  1.10554375e-01,   7.58561343e-02,  -1.65474042e-01, ...,\n",
       "             1.04459301e-01,   3.33962709e-01,   6.58478737e-02],\n",
       "          [ -2.35963371e-02,   8.14572349e-02,  -1.62545398e-01, ...,\n",
       "            -2.17374966e-01,   7.74744228e-02,   5.63551560e-02]]],\n",
       "\n",
       "\n",
       "        [[[ -2.05005202e-02,  -3.00293744e-01,   1.28242403e-01, ...,\n",
       "            -2.15477258e-01,  -1.33858338e-01,  -8.77786875e-02],\n",
       "          [  6.89464435e-02,  -2.45034397e-01,   2.07575291e-01, ...,\n",
       "             1.16201952e-01,   2.89037585e-01,  -1.54763073e-01],\n",
       "          [ -7.07884803e-02,   4.70925588e-03,  -1.65396016e-02, ...,\n",
       "            -4.30434972e-01,  -3.82756978e-01,   2.04333052e-01],\n",
       "          ..., \n",
       "          [ -1.83056548e-01,  -4.08939682e-02,  -2.31730919e-02, ...,\n",
       "            -2.09135339e-01,  -1.69872969e-01,   1.99879277e-02],\n",
       "          [ -1.84515521e-01,   1.06798606e-02,  -1.06451891e-01, ...,\n",
       "            -2.03702554e-01,  -1.31853610e-01,   5.98848276e-02],\n",
       "          [  3.32925096e-02,  -7.29171410e-02,   1.71967242e-02, ...,\n",
       "             1.60705224e-02,   9.60083529e-02,   9.80963707e-02]],\n",
       "\n",
       "         [[  6.65483251e-02,  -6.58848882e-02,  -3.84252369e-02, ...,\n",
       "            -4.20691699e-01,  -1.62848517e-01,   4.28900644e-02],\n",
       "          [ -2.05959767e-01,   1.53737860e-02,  -2.61273831e-01, ...,\n",
       "            -1.73338681e-01,   6.70327172e-02,  -1.52059913e-01],\n",
       "          [  7.01126382e-02,   8.72006789e-02,  -1.80090249e-01, ...,\n",
       "            -1.34311318e-01,  -6.10553548e-02,   1.75070614e-01],\n",
       "          ..., \n",
       "          [ -2.07404599e-01,   4.06380184e-02,  -2.53806412e-01, ...,\n",
       "             4.53502908e-02,   7.66229182e-02,  -2.20394321e-02],\n",
       "          [ -1.26224265e-01,  -6.22218475e-02,   5.03891706e-02, ...,\n",
       "             3.04038394e-02,   3.40851098e-02,   3.73925865e-02],\n",
       "          [ -9.25059617e-02,   5.25538661e-02,   9.60066915e-02, ...,\n",
       "            -1.53924167e-01,  -3.32302749e-02,  -1.77804902e-02]],\n",
       "\n",
       "         [[  8.15831721e-02,  -1.74324289e-01,   1.73975006e-01, ...,\n",
       "            -8.19332246e-03,  -2.57969588e-01,  -8.19973946e-02],\n",
       "          [ -4.52209681e-01,   4.11985628e-03,   1.08981222e-01, ...,\n",
       "            -1.25880450e-01,  -1.22404866e-01,  -1.41867086e-01],\n",
       "          [  1.58364505e-01,   7.02624326e-04,   2.16051504e-01, ...,\n",
       "             1.51745945e-01,   2.97383219e-02,   1.41059503e-01],\n",
       "          ..., \n",
       "          [  1.83756836e-03,  -1.24691240e-02,   1.26876369e-01, ...,\n",
       "            -3.32488939e-02,   5.68142161e-02,  -8.40758011e-02],\n",
       "          [ -1.54516682e-01,  -7.55086467e-02,  -3.66040990e-02, ...,\n",
       "             1.22784404e-02,   1.58868328e-01,   1.17759351e-02],\n",
       "          [ -1.67018875e-01,   4.74363603e-02,  -1.43852472e-01, ...,\n",
       "            -4.16044563e-01,  -1.02662034e-01,   3.12338467e-03]]]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}